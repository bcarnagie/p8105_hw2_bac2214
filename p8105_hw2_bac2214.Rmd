---
title: "p8105_hw2_bac2214"
author: "Brianna Carnagie"
date: "2023-10-02"
output: github_document
---

```{r, echo=FALSE, message=FALSE}
library(tidyverse)
library(lubridate)
library(readxl)
library(dplyr)
```

# Problem 1
#### Cleaning the first dataset
```{r, message=FALSE}
pols_month_df = 
  read_csv("data/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate_wider_delim(mon, "-", names = c("year","month","day")) |> 
  mutate(
    month = case_match(
    month,
    "01" ~ "jan",
    "02" ~ "feb",
    "03" ~ "mar",
    "04" ~ "apr",
    "05" ~ "may",
    "06" ~ "jun",
    "07" ~ "jul",
    "08" ~ "aug",
    "09" ~ "sep",
    "10" ~ "oct",
    "11" ~ "nov",
    "12" ~ "dec"), year = as.double(year)) |> 
  mutate(president = case_when(
     prez_dem == 1 ~ "dem",
    prez_gop == 1 ~ "gop",
    prez_gop == 2 ~ "gop"
  )) |> select(-prez_dem, -prez_gop, -day) 
``` 

#### Cleaning the second dataset
```{r, message=FALSE}
snp_df = 
  read_csv("data/snp.csv") |> 
  janitor::clean_names() |> 
  separate_wider_delim(date, "/", names = c("month", "day", "year")) |> 
  select(year, month,-day, close,) |> 
  mutate(
    month = case_match(
    month,
    "1" ~ "jan",
    "2" ~ "feb",
    "3" ~ "mar",
    "4" ~ "apr",
    "5" ~ "may",
    "6" ~ "jun",
    "7" ~ "jul",
    "8" ~ "aug",
    "9" ~ "sep",
    "10" ~ "oct",
    "11" ~ "nov",
    "12" ~ "dec")) |> mutate(year = as.double(year), year = year + 2000)
```

#### Cleaning the last dataset 
```{r, message=FALSE}
unemployment_df = 
  read_csv("data/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(jan:dec,
               names_to = "month",
               values_to = "unemployment_percentage") 
```
  
#### Merging the dataset
```{r}
fivethirtyeight_merge = 
  left_join(pols_month_df, snp_df) |>
  left_join(x = _, y = unemployment_df)
```

#### Making variables about the dataset
```{r}
min_year <- fivethirtyeight_merge |> 
  select(year) |> 
  pull() |> 
  min()

max_year <- fivethirtyeight_merge |> 
  select(year) |> 
  pull() |> 
  max()

num_rows = nrow(fivethirtyeight_merge)
num_col = ncol(fivethirtyeight_merge)
```

The data contains `r num_col` columns and `r num_rows` rows . I see that the first year of data is `r min_year`  while the most recent year is `r max_year`. The `month` and `year` variables were very important for merging the 3 datasets together. An abbreviation wasn't really necessary in this case, but it was good to keep consistent naming conventions across all 3 datasets.

## Problem 2

#### Cleaning the first dataset
```{r}
mr_trashwheel_df =
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N586") |> janitor::clean_names() |> mutate(homes_powered = (weight_tons * 500)/30, trashwheel_name = "mr_trashwheel", year = as.double(year)) |> relocate(trashwheel_name)
```

#### Cleaning the second dataset
```{r}
professor_trashwheel_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M108") |> janitor::clean_names() |> mutate(homes_powered = (weight_tons * 500)/30, trashwheel_name = "professor_trashwheel")|> relocate(trashwheel_name)
```

#### Cleaning the last dataset
```{r}
gwynnda_trashwheel_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:L157") |>     janitor::clean_names() |> mutate(homes_powered = (weight_tons * 500)/30, trashwheel_name = "gwynnda_trashwheel") |> relocate(trashwheel_name)
```

#### Binding all 3 datasets together
```{r}
trashwheel_bind_df = 
  bind_rows(mr_trashwheel_df, professor_trashwheel_df, gwynnda_trashwheel_df)
```

 
#### Making variables about the dataset
```{r}
num_rows2 = nrow(trashwheel_bind_df)
num_col2 = ncol(trashwheel_bind_df)

na_count = trashwheel_bind_df |> 
  pull(plastic_bags) |> 
  is.na() |> 
  sum()

cigbutts_count = trashwheel_bind_df |> 
  select(plastic_bags) |> 
  pull() |> 
  sum(na.rm = TRUE)
```

There are `r num_col2` columns and `r num_rows2` observations. I noticed that there are `r na_count` in the `plastic bag` variable due to the fact that `mr_trashwheel_df` and `professor_trashwheel_df` did not collect data for this variable. Cigarette butts seem be a huge contributor of trash, with all 3 trashwheels collecting a total of `r cigbutts_count` butts total. 


> For available data, what was the total weight of trash collected by Professor Trash Wheel?
```{r}
professortrashwheel_total_wt = trashwheel_bind_df |> 
  select(trashwheel_name, weight_tons) |> filter(trashwheel_name == "professor_trashwheel") |> 
  pull("weight_tons") |> 
  sum(na.rm = TRUE)
```

The total weight of trash collected by Professor Trash Wheel is `r professortrashwheel_total_wt` tons.


> What was the total number of cigarette butts collected by Gwynnda in July of 2021?
```{r}
gwynndatrashwheel_total_cigbutts = subset(trashwheel_bind_df,
  trashwheel_name == "gwynnda_trashwheel" &
  month == "July" &
  year == 2021) |> 
select(cigarette_butts) |> 
sum(na.rm = TRUE)  
```

The total number of cigarette butts collected by Gwynnda in July of 2021 was `r gwynndatrashwheel_total_cigbutts`.


## Problem 3
Import, clean, and tidy the dataset of baseline demographics. Ensure that sex and APOE4 carrier status are appropriate encoded (i.e. not numeric), and remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline). Discuss important steps in the import process and relevant features of the dataset. How many participants were recruited, and of these how many develop MCI? What is the average baseline age? What proportion of women in the study are APOE4 carriers?

#### Cleaning first dataset
```{r}
mci_bl =
  read_csv("data/MCI_baseline.csv", skip = 1) |> 
  janitor::clean_names() |> 
  mutate(sex = case_match(sex, 
                          0 ~ "female",
                          1 ~ "male"), 
         apoe4 = case_match(apoe4,
                          0 ~ "non_carrier",
                          1 ~ "carrier"),
       age_at_onset = case_when(
         age_at_onset == "." ~ "9999", # made periods a large arbitrary number
         TRUE ~ age_at_onset)) |> 
  mutate(age_condition = current_age != "." & current_age >= age_at_onset) # checking if anyone had mci prior to study enrollment 
```

An important step for me to take when importing this dataset was to skip the first row. This row contained information about the dataset, so I skipped it using the read_csv function so that the first row would be the column name. Important features in the dataset include the id which serves as a unique identifier for each patient and age on onset, with a missing value for this column indicating that the study participant remained MCI throughout the study period (which we wanted to exclude). Sine the age at baseline was either missing or greater than the age of participants at enrollment, I decided not to remove any particapnt since all of them seemed to meet inclusion criteria of no MCI at baseline.


>  How many participants were recruited, and of these how many develop MCI?
```{r}

total_particpants_count = read_csv("data/MCI_baseline.csv", skip = 1) |> 
  janitor::clean_names() |> 
  mutate(sex = case_match(sex, 
                          0 ~ "female",
                          1 ~ "male"), 
         apoe4 = case_match(apoe4,
                          0 ~ "non_carrier",
                          1 ~ "carrier")) |> nrow()
         
mci_during_enrollment = read_csv("data/MCI_baseline.csv", skip = 1) |> 
  janitor::clean_names() |> 
  mutate(sex = case_match(sex, 
                          0 ~ "female",
                          1 ~ "male"), 
         apoe4 = case_match(apoe4,
                          0 ~ "non_carrier",
                          1 ~ "carrier")) |>
         filter(age_at_onset != ".") |> nrow()
```

There were `r total_particpants_count` people recruited for the study and `r mci_during_enrollment` developed mci.

> What is the average baseline age?
```{r}
avg_age_bl = mci_bl |> 
pull(current_age) |> 
mean(na.rm = TRUE)
```

The average baseline age is `r avg_age_bl`.

#### Cleaning second dataset
```{r}
mci_amyloid = read_csv("data/mci_amyloid.csv", skip = 1) |>
   janitor::clean_names() |> 
   pivot_longer(
   baseline:time_8,
   names_to = "years_since_bl",
   values_to = "measurements",
   names_prefix = "time_"
) |> 
mutate(years_since_bl = replace(years_since_bl, years_since_bl =="baseline", "0")
) |> rename("id" = "study_id")
```

#### Making info about the variables
```{r}

na_count_mciamyloid = mci_amyloid |> 
  pull(measurements) |> 
  is.na() |> 
  sum()
  
mci_amyloid_rowtotal = mci_amyloid |> nrow()
```
I imported, cleaned and tidied the dataset ins cuh a way that all time_points are in one column instead of being split into separate columsn for baseline,time 2, etc. I also skippied the first row because this contained information about the dataset. There are `r mci_amyloid_rowtotal` measurements across all study participants and `r na_count_mciamyloid` NA values for the measurements variable.

> Check whether some participants appear in only the baseline or amyloid datasets.
```{r}
participants_in_bl = anti_join(mci_bl,mci_amyloid, by = "id")

participants_in_amyloid = anti_join(mci_amyloid, mci_bl, by = "id")

only_inamyloid_rows = nrow(participants_in_amyloid)

only_in_bl_rows = participants_in_bl |> 
distinct(id) |> 
nrow()
```
There are `r only_in_bl_rows` participants only appearing in the baseline dataset and `r only_inamyloid_rows` participants only in the amyloid dataset. 

##### Combining baseline and amyloid datasets only with participants having data in both 
```{r}
mci_merge =
  inner_join(mci_bl, mci_amyloid, by = "id")
  
only_in_both_rows = mci_merge |> 
distinct(id) |> 
nrow()

mci_merge_rows = 
  mci_merge |> nrow()
```
There are `r only_in_both_rows` unique individuals with data in both datasets. The dataset has `r mci_merge_rows` total observations.

#### Exporting as a csv
```{r}
write.csv(mci_merge, "mci_merge.csv")
```

